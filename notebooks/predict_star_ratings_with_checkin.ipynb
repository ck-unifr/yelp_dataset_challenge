{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the yelp dataset start rating classification problem.\n",
    "The objective is to predict the star rating based on the:\n",
    "- business review count\n",
    "- total number of checkins\n",
    "- state where business is located\n",
    "- city where business is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_json('../../data/business.json',lines=True)\n",
    "df_checkin = pd.read_json('../../data/checkin.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business['review_count'] = df_business['review_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business['stars'] = df_business['stars'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = df_business.groupby('stars').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = df_business.loc[:, ['latitude', 'longitude', 'review_count', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_standardized = (numeric_features)/numeric_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pairplot(numeric_features_standardized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df_business['latitude'])\n",
    "plt.show()\n",
    "ax = sns.distplot(df_business['longitude'])\n",
    "plt.show()\n",
    "ax = sns.distplot(df_business['stars'])\n",
    "plt.show()\n",
    "ax = sns.distplot(df_business['review_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='state', data=df_business)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('State distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='city', data=df_business)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('City distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business[\"stars\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import datetime\n",
    "#datetime_object = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkin_count(x):\n",
    "    return len(x.split(\", \"))\n",
    "\n",
    "df_checkin['checkin_count'] = df_checkin['date'].apply(get_checkin_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_checkin[\"checkin_count\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_business, df_checkin, on='business_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[['checkin_count']] = df_merged[['checkin_count']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new = df_merged[['business_id','review_count', 'stars', 'checkin_count', 'city', 'state', 'categories']]\n",
    "df_merged_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new['stars'] = df_merged_new['stars'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new['review_count'] = df_merged_new['review_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_to_norm = ['review_count', 'checkin_count']\n",
    "#new_df[cols_to_norm] = new_df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "dict_scaler = {}\n",
    "for col_to_norm in cols_to_norm:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_merged_new.loc[:, col_to_norm].values.reshape(-1, 1))\n",
    "    df_merged_new.loc[:,col_to_norm] = scaler.transform(df_merged_new.loc[:,col_to_norm].values.reshape(-1, 1))\n",
    "    dict_scaler[col_to_norm] = scaler  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform features of types string to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "cols_str_to_int = ['state', 'city']\n",
    "for col_str_to_int in cols_str_to_int:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    df_merged_new[col_str_to_int] = label_encoder.fit_transform(df_merged_new[col_str_to_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new['categories_str'] = df_merged_new['categories'].apply(lambda x:x.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set((', '.join(df_merged_new['categories'].tolist())).strip().split(', '))\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: one-hot encoding\n",
    "Due to limited computational resource, the categorical feature one-hot encoding is put into the todo list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text feature extraction \n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/45961747/append-tfidf-to-pandas-dataframe\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=100, min_df=2)\n",
    "x = vectorizer.fit_transform(categories)\n",
    "\n",
    "df_temp = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(df_temp)\n",
    "\n",
    "df_merged_new_tfid = pd.concat([df_merged_new, df_temp], axis=1)\n",
    "print(df_merged_new_tfid)\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_merged_new.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.matshow(corr)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "plt.yticks(range(len(corr.columns)), corr.columns);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_merged_new_tfid.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.matshow(corr)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "plt.yticks(range(len(corr.columns)), corr.columns);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict star ratings without using category text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merged_new[['review_count', 'checkin_count', 'city', 'state']]\n",
    "Y = df_merged_new['stars'].apply(int).tolist()\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_tfid = scaler.fit_transform(X_tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfid = df_merged_new_tfid[['review_count', 'checkin_count', 'city', 'state'] + vectorizer.get_feature_names()]\n",
    "\n",
    "X_tfid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfid.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfid, X_test_tfid, y_train, y_test = train_test_split(X_tfid, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_predict = random_forest.predict(X_test)\n",
    "\n",
    "#accuracy_score = accuracy_score(y_test, y_predict)\n",
    "#print(accuracy_score)\n",
    "\n",
    "print(f1_score(y_test, y_predict, average='macro'))  \n",
    "print(f1_score(y_test, y_predict, average='micro'))\n",
    "print(f1_score(y_test, y_predict, average='weighted'))  \n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "random_forest.fit(X_train_tfid.values, y_train_tfid)\n",
    "\n",
    "y_predict_tfid = random_forest.predict(X_test_tfid)\n",
    "\n",
    "#accuracy_score = accuracy_score(y_test_tfid, np.array(y_predict_tfid))\n",
    "#print(accuracy_score)\n",
    "\n",
    "print(f1_score(y_test, y_predict_tfid, average='macro'))  \n",
    "print(f1_score(y_test, y_predict_tfid, average='micro'))\n",
    "print(f1_score(y_test, y_predict_tfid, average='weighted'))  \n",
    "print(f1_score(y_test, y_predict_tfid, average=None))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_tfid, y_predict_tfid))\n",
    "\n",
    "print(classification_report(y_test_tfid, y_predict_tfid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/kai/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /Users/kai/anaconda3/lib/python3.6/site-packages (from xgboost)\n",
      "Requirement already satisfied: scipy in /Users/kai/anaconda3/lib/python3.6/site-packages (from xgboost)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: hyperopt in /Users/kai/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: scipy in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: nose in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: pymongo in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: six in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: networkx in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: future in /Users/kai/anaconda3/lib/python3.6/site-packages (from hyperopt)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/kai/anaconda3/lib/python3.6/site-packages (from networkx->hyperopt)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth=4, n_estimators=200, learning_rate=0.05)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "accuracy_score = accuracy_score(y_test, y_predict)\n",
    "print(accuracy_score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict star ratings with using category text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
