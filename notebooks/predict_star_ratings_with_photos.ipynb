{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the yelp dataset start rating classification problem. The objective is to predict the star rating based on photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /opt/conda/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /opt/conda/lib/python3.7/site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (6.0.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py) (1.15.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py) (1.12.0)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n",
    "!pip install pillow\n",
    "!pip install h5py\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import operator\n",
    "from random import shuffle\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, precision_recall_curve, precision_score, recall_score, average_precision_score \n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import callbacks, applications, optimizers\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_json('../../data/business.json',lines=True)\n",
    "df_photo = pd.read_json('../../data/photo.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA) and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business.dropna()\n",
    "df_business['review_count'] = df_business['review_count'].fillna(0)\n",
    "df_business['stars'] = round(df_business['stars'].fillna(0)).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_starts = df_business['stars'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_photo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_photo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_business, df_photo, on='business_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Due to limited computational resources, randomly select some samples from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new = df_merged.sample(frac=0.001, replace=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_photo_ids = df_merged_new['photo_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_new['photo_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../../data/yelp_photos/photos/{}.jpg'.format(df_merged_new['photo_id'].values[0])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../../data/yelp_photos/photos/{}.jpg'.format(df_merged_new['photo_id'].values[1])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open('../../data/yelp_photos/photos/{}.jpg'.format(df_merged_new['photo_id'].values[1]))\n",
    "# adjust width and height to your needs\n",
    "width = 128\n",
    "height = 128\n",
    "# use one of these filter options to resize the image\n",
    "#im2 = im1.resize((width, height), Image.NEAREST)      # use nearest neighbour\n",
    "#im3 = im1.resize((width, height), Image.BILINEAR)     # linear interpolation in a 2x2 environment\n",
    "#im4 = im1.resize((width, height), Image.BICUBIC)      # cubic spline interpolation in a 4x4 environment\n",
    "im5 = im1.resize((width, height), Image.ANTIALIAS)    # best down-sizing filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list_starts\n",
    "\n",
    "# Note due to computation cost images are resized to smaller sizes\n",
    "# img_width, img_height = 80, 80\n",
    "img_width, img_height = 100, 100\n",
    "\n",
    "\n",
    "img_x = []\n",
    "img_y = []\n",
    "\n",
    "# ------------\n",
    "# Get training and test images\n",
    "\n",
    "img_dir_path = \"../../data/yelp_photos/photos/\"\n",
    "#dirs = os.listdir(img_dir_path)\n",
    "\n",
    "# key: product id, value: image path\n",
    "dict_img_path = dict()\n",
    "\n",
    "for photo_id in list(list_photo_ids):\n",
    "#for file_name in dirs:\n",
    "#    file_path = os.path.join(img_dir_path, file_name)\n",
    "    file_path = '{}/{}.jpg'.format(img_dir_path, photo_id)\n",
    "    img = load_img(file_path)         # this is a PIL image\n",
    "    img_resize = img.resize((img_width, img_height), Image.ANTIALIAS)\n",
    "    x = img_to_array(img_resize)      # this is a Numpy array with shape (img_width, img_height, 3)\n",
    "    # x = x.reshape((1,) + x.shape)   # this is a Numpy array with shape (1, 3, img_width, img_height)\n",
    "    \n",
    "    img_x.append(x)\n",
    "    \n",
    "    y = df_merged_new[df_merged_new['photo_id']==photo_id]['stars'].values[0]\n",
    "    img_y.append(y)\n",
    "    \n",
    "    \n",
    "#combined = list(zip(img_x, img_y))\n",
    "#random.shuffle(combined)\n",
    "#img_x[:], img_y[:] = zip(*combined)\n",
    "#train_img_x = img_x[:round(0.7*len(list_photo_ids))]\n",
    "#train_img_y = img_y[:round(0.7*len(list_photo_ids))]\n",
    "#test_img_x = img_x[round(0.7*len(list_photo_ids)):]\n",
    "#test_img_y = img_y[round(0.7*len(list_photo_ids)):]\n",
    "\n",
    "\n",
    "train_img_x, test_img_x, train_img_y, test_img_y = train_test_split(img_x, img_y, test_size=0.3, random_state=42)\n",
    "\n",
    "train_img_x = np.array(train_img_x)\n",
    "train_img_y = np.array(train_img_y)\n",
    "test_img_x = np.array(test_img_x)\n",
    "test_img_y = np.array(test_img_y)\n",
    "\n",
    "print(train_img_x.shape)\n",
    "print(train_img_y.shape)\n",
    "print(test_img_x.shape)\n",
    "print(test_img_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "# Transform category to one-hot encoding\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(class_names)\n",
    "train_img_y = le.transform(train_img_y)\n",
    "test_img_y = le.transform(test_img_y)\n",
    "\n",
    "plt.hist(train_img_y.tolist(), range(min(train_img_y), max(train_img_y)+1))\n",
    "plt.show()\n",
    "print(set(train_img_y))\n",
    "\n",
    "#plt.hist(test_img_y.tolist(), range(min(test_img_y), max(test_img_y)+1))\n",
    "#plt.show()\n",
    "#print(set(test_img_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_y = to_categorical(train_img_y, num_classes = len(class_names))\n",
    "test_img_y = to_categorical(test_img_y, num_classes = len(class_names))\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "train_img_x, val_img_x, train_img_y, val_img_y = train_test_split(train_img_x, train_img_y, test_size = 0.1, random_state=42)\n",
    "\n",
    "print('train set shape')\n",
    "print(np.array(train_img_x).shape)\n",
    "print(np.array(train_img_y).shape)\n",
    "print('validation set shape')\n",
    "print(np.array(val_img_x).shape)\n",
    "print(np.array(val_img_y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_img_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# CNN hyperparameters\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "filters = [8, 8]\n",
    "kernel_sizes = [4, 4]\n",
    "strides = [2, 2]\n",
    "pooling_sizes = [2]\n",
    "\n",
    "str_parameters = '[epochs]{}-[batch_size]{}-[filters]{}-[kernel_sizes]{}-[strides]{}-[pooling_sizes]{}'.format(epochs,\n",
    "                                                                                                                batch_size,\n",
    "                                                                                                                '_'.join(str(x) for x in filters),\n",
    "                                                                                                                '_'.join(str(x) for x in kernel_sizes),\n",
    "                                                                                                                '_'.join(str(x) for x in strides),\n",
    "                                                                                                                '_'.join(str(x) for x in pooling_sizes),\n",
    "                                                                                                                )\n",
    "\n",
    "model_name = 'CNN' \n",
    "#model_name = 'VGG16'  # require GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# Define the CNN models\n",
    "\n",
    "model = None\n",
    "if model_name == 'CNN':\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = filters[0], kernel_size = (kernel_sizes[0], kernel_sizes[0]),\n",
    "                     padding = 'Same', strides=strides[0],  input_shape = (img_width, img_height, 3)),\n",
    "                     #activation ='relu',\n",
    "                    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = filters[1], kernel_size = (kernel_sizes[1], kernel_sizes[1]),\n",
    "                     padding = 'Same', strides=strides[1],\n",
    "                     #activation ='relu'\n",
    "                     ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPool2D(pool_size=(pooling_sizes[0], pooling_sizes[0])))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dense(128, kernel_initializer='glorot_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(len(class_names), activation = \"softmax\"))\n",
    "\n",
    "elif model_name == 'VGG16':\n",
    "    # use pre-trained VGG16\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "    add_model = Sequential()\n",
    "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "\n",
    "    add_model.add(Dense(256, kernel_initializer='glorot_uniform'))\n",
    "    # add_model.add(Dense(1, activation='sigmoid'))\n",
    "    add_model.add(BatchNormalization())\n",
    "    add_model.add(Activation('relu'))\n",
    "    add_model.add(Dropout(0.2))\n",
    "\n",
    "    add_model.add(Dense(len(class_names), activation=\"softmax\"))\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "\n",
    "    # model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "    #              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = optimizers.SGD(lr=1e-3, momentum=0.9) \n",
    "\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,               # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,                # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,    # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,     # divide each input by its std\n",
    "        zca_whitening=False,                    # apply ZCA whitening\n",
    "        rotation_range=10,                      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1,                       # randomly zoom image\n",
    "        width_shift_range=0.1,                  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,                 # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,                  # randomly flip images\n",
    "        vertical_flip=False)                    # randomly flip images\n",
    "\n",
    "datagen.fit(train_img_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# Train the CNN model\n",
    "history = model.fit_generator(datagen.flow(train_img_x, train_img_y, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (val_img_x, val_img_y),\n",
    "                              verbose = 2, steps_per_epoch=train_img_x.shape[0] // batch_size, callbacks=[learning_rate_reduction])\n",
    "\n",
    "\n",
    "# Training and validation curves\n",
    "# Plot the loss and accuracy curves for training and validation\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_dir = './models/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "model_path = ''\n",
    "if model_name == 'CNN':\n",
    "    model_path = '{}cat-cnn-model-{}.h5'.format(model_dir, str_parameters)\n",
    "elif model_name == 'VGG16':\n",
    "    model_path = '{}cat-vgg16-{}-{}.h5'.format(model_dir, epochs, batch_size)\n",
    "model.save(model_path)\n",
    "print('save model to {}'.format(model_path))\n",
    "\n",
    "model_weights_path = ''\n",
    "if model_name == 'CNN':\n",
    "    model_weights_path = '{}cat-cnn-weights-{}.h5'.format(model_dir, str_parameters)\n",
    "elif model_name == 'VGG16':\n",
    "    model_weights_path = '{}cat-vgg16-weights-{}-{}.h5'.format(model_dir, epochs, batch_size)\n",
    "model.save_weights(model_weights_path)\n",
    "print('save weights to {}'.format(model_weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "model.load_weights(model_weights_path)\n",
    "\n",
    "test_pred = model.predict(test_img_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_classes = np.argmax(test_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# convert predictions classes to one hot vectors\n",
    "test_pred_classes = np.argmax(test_pred, axis = 1)\n",
    "# results = pd.Series(test_pred_classes, name=\"Label\")\n",
    "\n",
    "# convert test observations to one hot vectors\n",
    "test_true_classes = np.argmax(test_img_y, axis = 1)\n",
    "\n",
    "acc_score = accuracy_score(test_true_classes, test_pred_classes)\n",
    "print('accuracy {}'.format(acc_score))\n",
    "\n",
    "# compute the confusion matrix\n",
    "test_true_classes = le.inverse_transform(test_true_classes)\n",
    "test_pred_classes = le.inverse_transform(test_pred_classes)\n",
    "\n",
    "\n",
    "#print(classification_report(test_true_classes, test_pred_classes, target_names=class_names))\n",
    "print(classification_report(test_true_classes, test_pred_classes, target_names=[str(i) for i in list(set(test_true_classes))]))\n",
    "\n",
    "\n",
    "confusion_mtx = confusion_matrix(test_true_classes, test_pred_classes)\n",
    "#display(confusion_mtx[0:5][0:5])\n",
    "\n",
    "#plot the confusion matrix\n",
    "#confusion_mtx = confusion_mtx\n",
    "#plot_confusion_matrix(confusion_mtx, classes = range(len(class_names)))\n",
    "#plt.show()\n",
    "\n",
    "precision = precision_score(test_true_classes, test_pred_classes, average=None)\n",
    "recall = recall_score(test_true_classes, test_pred_classes, average=None)\n",
    "f1 = f1_score(test_true_classes, test_pred_classes, average=None)\n",
    "\n",
    "print('precision')\n",
    "print(precision)\n",
    "\n",
    "print('recall')\n",
    "print(recall)\n",
    "\n",
    "print('f1')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
